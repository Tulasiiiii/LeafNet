# -*- coding: utf-8 -*-
"""LeafNet

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CjX5nco01T2g00e0Z1BUjklL6R9ASmju
"""

!pip install opencv-python
!pip install tensorflow==2.6.0
!pip install tensorflow --upgrade --user
!pip install pip --upgrade --user

#importing libraries
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers,models
import matplotlib.pyplot as plt
import cv2
import os
import PIL
import numpy as np
import pathlib
import glob

from google.colab import drive
drive.mount('/content/drive')

#assigning directory
directory=pathlib.Path("/content/drive/My Drive/segmented_plant_village")

# Just needed in case you'd like to append it to an array
data = []

for filename in os.listdir("."):
    if filename.endswith("jpg"):
        # Your code comes here such as
        print(filename)
        data.append(filename)

#count of images in the directory given
image_count=len(list(directory.glob('*/*.jpg')))
#print(list(directory.glob('/*.jpg')))
image_count

#creating dictionary of flower species
flower_images_dict={
    "StrawberryLeafscorch":list(directory.glob('StrawberryLeafscorch/*.jpg')),
    "Potatohealthy":list(directory.glob('Potatohealthy/*.jpg')),
     "AppleApplescab":list(directory.glob('AppleApplescab/*.jpg')),
    "Blueberryhealthy":list(directory.glob('Blueberryhealthy/*.jpg')),
    "TomatoLeafMold":list(directory.glob('TomatoLeafMold/*.jpg'))

}

flower_images_dict

#Different species list
keys=["StrawberryLeafscorch", "Potatohealthy", "AppleApplescab", "Blueberryhealthy", "TomatoLeafMold"]

#resizing and creating labels using computer vision
resized,labels=[],[]
for flower_name,images in flower_images_dict.items():
    for image in images:
        print("completed")
        img=cv2.imread(str(image))
        resized_image=cv2.resize(img,(224,224))
        resized.append(resized_image)
        labels.append(keys.index(flower_name))
flower_images_dict

#function to print images
def print_image(i,j):
    plt.imshow(i)
    plt.title(keys[j])

#splitting data into train and test
#if any integer is given to random_state it will generate and give same set of data each time we run the code and if we give
#None different sequences will be generated
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(resized,labels,test_size=0.25,random_state=0)

print_image(x_train[15],y_train[15])

print_image(x_test[6],y_test[6])

print_image(x_test[20],y_test[20])

#normalizing data
x_train_scaled=np.array(x_train)/255
x_test_scaled=np.array(x_test)/255

x_train_scaled.shape

y_train=np.array(y_train)
y_train.shape

"""#Simple CNN Model"""

model=models.Sequential([
    layers.Conv2D(16,3,padding='same',activation='relu',),
    layers.MaxPooling2D(),
    layers.Flatten(),
    layers.Dense(128,activation="relu"),
    layers.Dense(5,activation="softmax")])
model.compile(
optimizer="adam",loss="sparse_categorical_crossentropy",metrics=["accuracy"])

model.fit(x_train_scaled,np.array(y_train),epochs=3)

model.evaluate(x_test_scaled,np.array(y_test))

!pip install visualkeras
import visualkeras

visualkeras.layered_view(model)

"""#CNN Model With Data Augumentation layers and Dropout layers"""

model1=models.Sequential([
    layers.experimental.preprocessing.RandomZoom(0.3),
    layers.Conv2D(16,3,padding='same',activation='relu'),
    layers.MaxPooling2D(),
    layers.Flatten(),
    layers.Dense(128,activation="relu"),
    layers.Dropout(0.3),
    layers.Dense(64,activation="relu"),
    layers.Dropout(0.3),
    layers.Dense(2,activation="softmax")
    #layers.Dense(2,kernel_regularizer=l2(0.01),activation="softmax")
])
model1.compile(
optimizer="adam",loss="sparse_categorical_crossentropy",metrics=["accuracy"])

model1.fit(x_train_scaled,np.array(y_train),epochs=5)

model1.evaluate(x_test_scaled,np.array(y_test))

visualkeras.layered_view(model)

"""#CNN Model with only Dropout layers"""

model2=models.Sequential([
    layers.MaxPooling2D(),
    layers.Flatten(),
    layers.Dense(128,activation="relu"),
    layers.Dropout(0.3),
    layers.Dense(64,activation="relu"),
    layers.Dropout(0.3),
    layers.Dense(2,activation="softmax")
])
model2.compile(
optimizer="adam",loss="sparse_categorical_crossentropy",metrics=["accuracy"])

model2.fit(x_train_scaled,np.array(y_train),epochs=15)

model2.evaluate(x_test_scaled,np.array(y_test))

visualkeras.layered_view(model)

"""#CNN Model only with Augumentation layers"""

model3=models.Sequential([
    layers.experimental.preprocessing.RandomZoom(0.3),
    layers.Conv2D(16,3,padding='same',activation='relu'),
    layers.MaxPooling2D(),
    layers.Flatten(),
    layers.Dense(128,activation="relu"),
    layers.Dropout(0.3),
    layers.Dense(64,activation="relu"),
    layers.Dense(32,activation="relu"),
    layers.Dense(2,activation="softmax")
])
model3.compile(
optimizer="adam",loss="sparse_categorical_crossentropy",metrics=["accuracy"])

model3.fit(x_train_scaled,np.array(y_train),epochs=5)

model3.evaluate(x_test_scaled,np.array(y_test))

visualkeras.layered_view(model)

"""#CNN Model with two different augumentation layers"""

model4=models.Sequential([
    layers.experimental.preprocessing.RandomZoom(0.3),
    layers.experimental.preprocessing.RandomFlip(mode="horizontal_and_vertical"),
    layers.Conv2D(16,3,padding='same',activation='relu'),
    layers.MaxPooling2D(),
    layers.Flatten(),
    layers.Dense(128,activation="relu"),
    layers.Dense(2,activation="softmax")
])
model4.compile(
optimizer="adam",loss="sparse_categorical_crossentropy",metrics=["accuracy"])

model4.fit(x_train_scaled,np.array(y_train),epochs=5)

model4.evaluate(x_test_scaled,np.array(y_test))

visualkeras.layered_view(model)

"""#CNN Model with Data Augumentation layer and more dense layers"""

model5=models.Sequential([
    layers.experimental.preprocessing.RandomZoom(0.3),
    layers.Conv2D(16,3,padding='same',activation='relu'),
    layers.MaxPooling2D(),
    layers.Flatten(),
    layers.Dense(128,activation="relu"),
    layers.Dense(64,activation="relu"),
    layers.Dense(32,activation="relu"),
    layers.Dense(2,activation="softmax")
])
model5.compile(
optimizer="adam",loss="sparse_categorical_crossentropy",metrics=["accuracy"])

model5.fit(x_train_scaled,np.array(y_train),epochs=5)

model5.evaluate(x_test_scaled,np.array(y_test))

visualkeras.layered_view(model)

"""#CNN MODEL THAT USES FILTERS IN ALL THE LAYERS"""

myCNN=tf.keras.models.Sequential([
    layers.BatchNormalization(),
    layers.Conv2D(32,3,activation="relu"),
    layers.MaxPooling2D(),
    layers.Conv2D(64,3,activation="relu"),
    layers.MaxPooling2D(),
    layers.Conv2D(128,3,activation="relu"),
    layers.MaxPooling2D(),
    layers.Flatten(),
    layers.Dense(256,activation="relu"),
    layers.Dense(2,activation="softmax")
])
myCNN.compile(optimizer="adam",loss="sparse_categorical_crossentropy",metrics=["accuracy"])

myCNN.fit(x_train_scaled,np.array(y_train),epochs=5)

myCNN.evaluate(x_test_scaled,np.array(y_test))

visualkeras.layered_view(model)